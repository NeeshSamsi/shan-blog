---
title: Understanding Algorithmic Bias
description: >-
  Machine learning models are transforming decision-making and resource
  allocation. How can these algorithms, essentially complex mathematical
  functions, exhibit as human an error as racial bias? Data has evolved into an
  intricate mirror that reflects the complexities of our society, compelling us
  to confront the ethical challenges posed by algorithmic decision-making.
authors:
  - shan
categories:
  - artificial-intelligence
  - ethics
image: /images/blogposts/understanding-algorithmic-bias/image.jpg
imageAlt: DALL.E Art Depicting Bias
pubDate: '2023-06-10'
updatedDate: '2023-06-10'
---
## The Rise of Machine Learning Models Machine learning models have become

indispensable tools across institutions of all forms and sizes, revolutionizing the way decisions are made and resources are allocated. Why bear the recurrent cost of maintaining a panel of recruiters with limited working hours, when the cream-of-the-crop resumes can be curated as they arrive? Why police areas indiscriminately, when resources can be concentrated selectively at high-risk sites? Why bother with ads for a general population, when they can be targeted to groups that are actually interested? Predictive technologies have massively optimized the time and costs associated with traditional decision-making. That said, reducing their significance to mere affordability would be naive. Since 1997, when IBM’s Deep Blue program dethroned the world chess champion, Garry Kasparov, machine learning models have become increasingly comparable to human experts in many diverse fields, even outperforming them in unexpected ways. In 2019, for instance, Google’s deep learning algorithm achieved a 99.4% reduction in error compared to the average human radiologist in detecting breast cancer from mammograms. The improvement curve for these technologies is near its steepest and it only gets better from here. Given how impressive these models are, it’s no surprise that people are jumping aboard the AI bandwagon. For developing countries like India, the embrace of AI is also influenced by its symbolic association with modernity and progress. Due to its public conception as “neutral” and “human-free”, AI has also gained undue algorithmic authority over human decision-makers. Machines are considered more rational than humans, and little analysis goes into questioning their inner workings and impact. From personal beliefs to a bad morning coffee, human judgments are subject to countless non-objective factors. As Daniel Kahneman elucidates in his writings, this irrationality can take the form of a brilliant intuitive insight or simply a bad decision. Machine learning models are immune to such human factors, thereby being “neutral” in some sense. However, they are far from immune to bias. ## Algorithmic Bias and a Fruity Experiment > “Face by face the answers seem uncertainYoung and old, proud icons are dismissedCan machines ever see my queens as I view them?Can machines ever see our grandmothers as we knew them?” >

> — From "AI, Ain't I a Woman" by Joy Buolamwini In a 2018 [research](https://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf), Joy Buolamwini revealed various axes of disparity in commercial gender classification models. Most strikingly, that there was a 34.7% error rate for dark-skinned women, as opposed to a mere 0.8% for light-skinned men. While these errors may be dismissed as inevitable in the early stages of these technologies, they elicit a deeper analysis. How does an algorithm, fundamentally just a complex mathematical function, come to demonstrate as human an error as racial bias? To understand, let’s get to know the algorithms in question. A human may use visual features like shape, color, texture to classify visual input. A round, red and shiny object, for example, is most likely a balloon. While humans rely on such intuitive visual features, machine learning models extract abstract features from the images that are impossible for us to comprehend. During training, the model learns to recognize these patterns and abstract features in the training data, enabling it to generalize and make predictions on new, unseen images. To isolate the effect of training data on a machine learning model, here’s a little experiment.
